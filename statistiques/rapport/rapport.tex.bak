\documentclass{report}
\usepackage{graphicx}
\usepackage[francais]{babel}
\usepackage[utf8]{inputenc}  
%\usepackage[T1]{fontenc}
\usepackage{amsfonts}
\usepackage{hyperref}
\usepackage{color}


\DeclareGraphicsExtensions{.pdf,.jpeg,.png,.ps} 
\graphicspath{{images/}} 

% (1) choose a font that is available as T1
% for example:
\usepackage{lmodern}

% (2) specify encoding
\usepackage[T1]{fontenc}

% (3) load symbol definitions
\usepackage{textcomp}

%-------------------------------------------maths ---------------------------------------------
\usepackage{amsthm}
\newtheorem{mydef}{Definition}
%------------------------------------------- code ---------------------------------------------
\usepackage{minted}
%-----------------------------------------------------------------------------------------------

%-----------------------------------------------------------------------------------------------

\begin{document}
\title{Rapport probabilistic model}
\author{CARRARA Nicolas}
\date{Le 24 juillet 2014}
\tableofcontents

%-----------------------------------------------------------------------------------------------


\part{Introduction}

Ce rapport s'inscrit dans une étude des champs neuronaux dynamiques. Jusqu'alors nous travaillons sur le modèle CNFT (INSERT REF HERE) . Rappelons tout d'abord en quoi consiste ce modèle. Nous avons un réseau de neurones. Chaque neurone est connecté avec l'ensemble des autres neurones. Chaque neurone dispose d'un seuil d'activation. Après avoir reçu une charge suffisamment importante en tension, le neurone s'active et envoie un signal aux neurones afférents. Cet envoie suit un routage bien particulier. L'idée est d'envoyer des tensions plus faibles aux neurones les plus éloignés en suivant une courbe type différence de deux gaussiennes. Le problème de ce modèle est qu'il requière une interconnexion de neurones globale. Chaque neurone est lié aux autres neurones. Cet état de fait implique qu'il sera difficile d'implémenter ce routage sur une carte FPGA par exemple. 

Afin d'alléger le modèle dans son ensemble, on va s'intéresser à des type de routage qui ne nécessite pas autant de connexions neurales. Ce rapport a donc pour objectif d'exposer les différents outils mis à disposition afin de tester différents routages dans le cadre de ce modèle. On va voir comment générer des données relatifs à ce routage et comment les analyser. La mise en pratique sera faite sur le routage "Probabilistic flooding" (INSERT REF HERE)


%-----------------------------------------------------------------------------------------------

\part{Stimulus}

\section{Objectif}

On peut exciter chacun des nœuds du graphe à différents moments. L'objectif est de voir le comportement du graphe (et du routage associé) selon différents événements. Ces événements sont caractérisés par l'envoie de stimulus, i.e l'ajout de paquet à la file d'attente d'un ou plusieurs nœuds à un ou plusieurs moments de la simulation.

\section{Utilisation}

Le framework pour la programmation d'envoi de stimulus se base sur le format xml. Tout les fichiers de programmation doivent se trouver sous le dossier statistiques/stimulis avec l'extension .stimulis (et non .xml). Cette extension est nécessaire aux fichiers de scripts notamment.

Commençons par un exemple. Admettons que l'on veuille envoyer un paquet de type spike au nœud zéro du graphe à l'instant t=0 :
\\
\inputminted[linenos=true,frame=single,label=asend.stimulis]{xml}{/home/nikolai/Work/Loria2014/dnfsim2/statistiques/stimulis/a_send.stimulis}

On retrouve ici trois balise :
\\
\begin{itemize}
\item <programation> : On stipule qu'on va commencer un programme d'envoi stimulis (il y a une faute à "programation" mais  j'ai codé ça comme ça). L'attribut "class" est le nom de la class Java des paquets que l'on veut envoyer en tant que stimulis.
\item <time> : Pour spécifier les envois à un temps t donné. A noté que 

\[dtStimulis = k\ *\ dtGraphe\ \forall{k \epsilon{\mathbb{N}^*}}   \] 

i.e on ne peut pas envoyer des stimulis entre deux computations.
\item <add> : On envoie un paquet à l'indice indice. Notez que les indices sont en représentation 1D du graphe.
\end{itemize}

Un exemple d'envoi de paquets ipv4 sur un réseau :\\

\inputminted[linenos=true,frame=single,label=ipv4.stimulis]{xml}{/home/nikolai/Work/Loria2014/dnfsim2/statistiques/stimulis/ipv4.stimulis}

On découvre la balise <params>. L'utilisation de cette balise est directement liée à la structure du constructeur de la class spécifiée dans la balise programation. Dans l'exemple précédent on utilisait des spikes, objet simple ne prenant aucun paramètre lors de la construction, on a pas eu besoin d'utiliser la balise <params>. Par contre un paquet ipv4 transporte un message. Ce message est "A". Les valeurs "yes" et "ça fonctionne !" n'ont aucun effet sur la construction d'un objet ipv4 vu qu'il ne prend qu'un string en params.\\

Il faut regarder de plus près le code java.\\



\begin{minted}[linenos=true,frame=single,label=Packet.java]{java}
public class Packet {

    private int size;    
  
    protected Packet(Object ... params){
    }
    
    //...
    
\end{minted}

Chaque classe fille de Packet doit implémenter le constructeur protected.(ça doit être le premier constructeur dans le code pour des raisons d'introspection, même si il y a moyen de faire mieux).\\

\begin{minted}[linenos=true,frame=single,label=Spike.java]{java}
public final class Spike extends Packet {

    public Spike(Object ... params) {
        setSize(1);
    }

}
\end{minted}

On voit que Spike n'utilise aucun de ses paramètres.\\

\begin{minted}[linenos=true,frame=single,label=IPv4Datagramme.java]{java}
public final class IPv4Datagramme extends Packet{
	
	private String message;
	
	public static final int MESSAGE_INDEX = 0;
	
	public IPv4Datagramme(Object ... params) {
        setSize(16); 
        setMessage((String)params[MESSAGE_INDEX]);
	}
	
	//...
\end{minted}

IPv4 utilise un seul paramètre. A noté que les objets récupérés seront de type String.\\


%-----------------------------------------------------------------------------------------------
\part{Génération de données}

\section{Introduction}

Afin de tester certaines propriétés du graphe, il est nécessaire de générer un jeu de donnée conséquent concernant différents caractéristiques du routage.

\section{Spikes reçus jusqu'alors}

Dans cette section, nous allons nous intéressé à la génération du jeu de donnée représentant la quantité de spike reçu par chaque nœud du graphe, de l'instant 0 à l'instant t.
Pour ce faire, il faut utiliser le script generateData.py.
Ce script s'occupe de lancer cette expérience :\\

\textit{J'ai un graphe de routage type probabilistic flooding model, j'envoie des stimulis à un ou plusieurs moments de la propagation. Ce graphe a une taille et un poids (probabilité de détruire un spike sortant d'un nœud). Je laisse tourner la propagation pendant t secondes.Je récupère la matrice représentant le nombre total de spikes reçus par chaque nœuds jusqu'à l'instant t}\\

On lance cette expérience plusieurs fois (itérations) et selon différents paramètres (taille, poids, programmation des stimulis).

Un exemple d'appel de cette commande :
\begin{minted}[frame=single]{python}
python generateData.py --weigths 0.0 0.1 0.2 0.3 0.4 --times 1 2 
--packet_initialisation twoa twob twoab --iterations 100 
--tailles_grilles 9 --forcerewrite
\end{minted}

Ici on génère les données pour les combinaisons de poids temps. On stipule que ce sera de 
taille 9 mais on aurait pu écrire 
\begin{minted}[frame=single]{python} 
--taille_grilles 1 2 3 4 5 6 7
\end{minted}


On veut que l'expérience soit réalisée selon plusieurs programmations (twoa twob et twoab). Les dites programmation doivent se trouver dans le dossier statistiques/stimulis sous la forme nom.stimulis (exemple : twoab.stimulis).

Les données générées se trouvent sous le dossier statistiques/data (avec une arborescence dépendante des paramètres).

A noter que ce script n'est utilisable qu'avec le PFModel pour le moment mais il est facilement extensible à d'autre modèles.\\\\
Faire
\begin{minted}[frame=single]{python}
python generateData.py --help
\end{minted}
pour plus d'informations

%-----------------------------------------------------------------------------------------------

\part{Additivité}

Il est nécessaire de conserver la propriété d'additivité du réseau lors de l'utilisation de nouveaux routages. Pour cela, posons une définition théorique de l'additivité.

\section{Théorie( à finir)}

A partir de maintenant, on considère un graphe G(N,E) avec N l'ensemble de ses nœuds et E l'ensemble de ses arêtes. Chaque nœud possède une file d'attente FIFO. On peut lancer une propagation sur ce graphe.

\begin{mydef}
(Paquet)
{\color{red}(PAS ASSEZ RIGOUREUX)}

Un \textbf{paquet} $\mathtt{p}$ est un objet. Il contient un certain nombre d'informations. Il se déplace sur le graphe de nœuds en nœuds au fil du temps (lors de la propagation du graphe).
Si le \textbf{paquet} ne contient aucune information, on parle de \textbf{spike}.
\end{mydef}

\begin{mydef}
(Stimulis)

Un \textbf{stimulis} $\mathtt{S}_{p,n,t}$ est le placement du paquet $\mathtt{p}$ dans la file d'attente du nœud n à l'instant t. Si t=0 et si p est un spike, on parle alors d' \textbf{activation}. Une \textbf{activation} $\mathtt{A}_{n}$ est le \textbf{stimulis} $\mathtt{S}_{s,n,0}$
\end{mydef}

\begin{mydef}
(Configuration)

Une \textbf{configuration} $\mathtt{C}$ est un ensemble de stimulis. On parle d'initialisation $\mathtt{I}$ si c'est un ensemble d'activation.
\end{mydef}

\begin{mydef}
(Additivité)

Soit $\mathtt{A^0},\mathtt{A^1}, .. ,\mathtt{A^K}$ des activations où $\mathtt{A^i}=\mathtt{A}_{n_i} \forall i$.

On pose l'initialisation $\mathtt{I}=\{\mathtt{A^k}\ |\ n\epsilon[0,K]\ et\ K>0\}\  $ 

On pose $\mathtt{I}_k = \{\mathtt{A^k}\}\ \forall n\epsilon[0,K]$\\

Soit $M_{t,n,\mathtt{I}}$ la variable aléatoire qui représente l'ensemble des paquets reçus par le nœud n depuis le début de la propagation pour chaque nœud du graphe à l'instant t selon l'initialisation $\mathtt{I}$.\\

On pose $M_{t,\mathtt{I}}=(M_{t,0,\mathtt{I}},M_{t,1,\mathtt{I}},...,M_{t,card(N),\mathtt{I}})$ et $M_{t,\mathtt{I}_i}=(M_{t,0,\mathtt{I}_i},M_{t,1,\mathtt{I}_i},...,M_{t,card(N),\mathtt{I}_i})$ \\

On dit que le routage est \textbf{additif pour l'initialisation} $\mathtt{I}\ si\ \forall t$  

\[\mathbb{E} (M_{t,\mathtt{I}}) = \sum_{i=1}^{n} (\mathbb{E} (M_{t,\mathtt{I}_i})) \]\\

On dit qu'un routage est \textbf{additif} si il l'est pour n'importe quelle initialisation.\\

Note : On pourrait parler d'additivité pour une configuration qui n'utilise que des spikes, et pas forcement une initialisation.
\end{mydef}

\section{Utilisation du script}

Afin de tester cette propriété d'additivité sur des résultats expérimentaux, nous avons crée un script en Scilab. Ce dernier lit un ensemble de donnée de plusieurs répétition d'expériences afin d'extraire une moyenne de ces données, puis il va calculer à quel point le routage est additif sur ces résultats moyens.


Par exemple 
\begin{minted}[frame=single]{python} 
scilab -nw -f Additivite.sce -args '9' '1 2' 
'0.0 0.1 0.2 0.3 0.4' '5 20 50 75 100' 
'twoa twob' twoab 0 
\end{minted}

vérifie l'additivité twoa+twob=twoab sur les combinaisons possibles entre\\

\begin{itemize}
	\item tailles : 9
	\item times : 1 2 (secondes)
	\item poids : 0.0 0.1 0.2 0.3 0.4
	\item tailles échantillons : 5 20 50 75 100 (nombre de répétition de l'expérience)
\end{itemize}

\section{Résultats}

On lance le script avec taille 9 dt 0.1 et time 5s.
\href{run:images/additivite2.png}{Sur l'image suivante} on remarque qu'a partir d'un certain temps de computation, on a une additivité maximale autour de 0.7. On remarque aussi que l'activité fluctue bien moins quand on augmente le nombre d'expériences. Cette dernière observation pourrait nous amener à la conclusion qu'il faille lancer plusieurs spikes en même temps par activation de neurone (on simulerait en quelque sorte la répétition d'expérience même si on a aucune garantie que le comportement soit similaire. C'est à tester).

{\color{red}\{TODO pourquoi c'est meilleurs en 0.7 et pas en 0.0 ?\}}

\href{run:images/additivite3.png}{En zoomant} autour de 0.7 on trouve une valeur minimale de finesse en 0.72.
A noter que cette valeur n'est valable que pour cette configuration (taille 9 time 5s dt 0.1)

%-----------------------------------------------------------------------------------------------

\part{Propagation des spikes}

Pour qu'un nouveau model soit viable, en plus d'avoir un comportement additif, il doit avec une répartition voltaïque de type "différence de deux gaussienne". Dans cette partie on va voir comment vérifier cette propriété et si notre modèle "Probabilistic flooding" permet d'obtenir la répartition désirée.

\section{Utilisation du script}

Le script MeanAndVariance.sce permet d'obtenir les statistiques moyennes variances et écart type sur un échantillon d'expérience et ce en utilisant différents paramètres. Un exemple de cette commande : 

\begin{minted}[frame=single]{python} 
scilab -nw -f MeanAndVariance.sce -args 
9 '1 3 5' '0.7' 1000 a_send_20 temp/
\end{minted}

avec respectivement comme arguments :

\begin{itemize}
  \item 9 : la taille du réseau (la racine)
  \item '1 3 5' : les temps de computations 
  \item '0.3 0.7' : les poids
  \item 1000 :le nombre d'expérience qu'on utilise pour calculer nos statistiques
  \item a\textunderscore send\textunderscore 20 : le scénario des expérience (a \textunderscore send \textunderscore 20.stimulis doit de trouver sous le dossier stimulis/)
  \item temp/ : le dossier sous lequel les images vont être enregistrer
\end{itemize}

Cette commande va générer sous le dossier temp un ensemble de graphique représentant les 3 statistiques sur l'ensemble du graphe et sur la diagonale.

\section{Résultats}

On voit sur \href{run:images/global_spike_data_diag1_moyenne_inita_send_taille9.png}{l'image ci contre} que c'est avec un poids de 0.7 et un temps de computation de 3s qu'on obtient une courbe proche de ce que l'on cherche.

Le problème c'est que l'écart type est élevé comme on peut le voir \href{run:images/global_spike_data_diag1_ecart type_inita_send_taille9.png}{sur cette image}. 

\section{Réflexions}

Afin de voir si ce modèle est fiable et pas trop aléatoire on se penche sur le calcul d'un intervalle de confiance autour de la moyenne. Le seul problème c'est que la distribution ne suit pas une loi de probabilité connu,comme on peut le voir sur \href{run:images/violin.png}{cette image}, du coup on pourrait s'orienter vers des méthodes bootstrap.

%-----------------------------------------------------------------------------------------------
\part{Probabilistic flooding et I/E}

On rappelle que l'objectif est de trouver un modèle de réseau neural simulant le comportement de DNF tout en consommant moins de ressource. Pour cela on va utiliser le routage probabilitic flooding. Ce routage comme vu précédemment s'avère additif et suit une distribution exponentielle/gaussienne selon certains paramètre. On a donc le candidat idéal pour simuler le routage originel de DNF. On va donc mettre en place de couche de graphes utilisant le routage PF (probabilitic flooding). Une couche avec des signaux excitateurs et une autre avec des signaux inhibiteurs. On applique une transformation affine a ce deux couches puis on soustrait l'une et l'autre. On obtient à la fin la distribution du potentiel des neurones en fonction de leur éloignement aux stimulis. On veut que cette distribution ressemble à la différence de gaussienne du routage de DNF. Pour ça on doit trouver les paramètres des transformations affines ainsi que les poids et les temps de computations des deux graphes. C'est le script InhibiteurExcitateur.sce qui nous permet d'observer l'effet de tel ou tel paramètre sur le comportement voltaïque du réseau de neurones.

\section{Utilisation du script}

Je n'ai pas fais de mode bash sur le script InhibiteurExcitateur.sce (todo?), donc pour l'utiliser il faudra  modifier directement le fichier scilab. Pour cela on a plusieurs paramètres : 

\begin{minted}[frame=single]{python}
w_inhib = 0.5; 
w_excit = 0.7;
t_inhib = 3;
t_excit = 5;
taille = 19;
aE = 1;
aI = 1;
bE = 0;
bI = 0;
initialisation_packet = 'a_send_20';
maxiteration = 1000;
\end{minted}

\begin{itemize}
	\item w\textunderscore inhib : le poids des nœuds du réseau inhibiteur (RI)
	\item w\textunderscore excit : le poids des nœuds du réseau excitateur (RE)
	\item t\textunderscore inhib : le temps de computation du RI
	\item t\textunderscore excit : le temps de computation du RE
	\item taille : la taille du réseau de neurone
	\item aE : coefficient directeur de la transformation affine sur le RE
	\item aI :  coefficient directeur de la transformation affine sur le RI
	\item bE :	 base de la transformation affine sur le RE
	\item bI :  base de la transformation affine sur le RI
	\item initialisation\textunderscore packet :  configuration des stimulis 
	\item maxiteration :  nombre de répétition de l'expérience
\end{itemize}

\section{Résultats}

On veut obtenir une courbe de \href{run:images/figure_1.png}{cette forme}. Pour ça on pose comme paramètres : 

\begin{itemize}
	\item w\textunderscore inhib = 0.5
	\item w\textunderscore excit = 0.7
	\item t\textunderscore inhib = 3
	\item t\textunderscore excit = 5
	\item aE = 0.1714286
	\item aI = 0.0428571
	\item bE = -0.5
	\item bI = 0.0
\end{itemize}

Et on récupère une courbe de \href{run:images/InhibExit2.png}{cette forme}. La correspondance nous a semblé suffisante pour des tests en conditions réelles.

\section{Application sur dnfsim}

On va donc utiliser cette combinaison linéaire de Probabilistic flooding graphes afin de simuler DNF. Pour cela, on incorpore les différents graphes au logiciel dnfsim. On run un scénario avec deux bulles à des positions opposées qui tournent. Ça fonctionne très mal, la variance est très élevée, on a rarement le focus d'une bulle. Pour palier à ce problème de variance on s'oriente sur l'envoi de {\{20,40,60,80\} spikes par activation de neurone pour voir ce que ça donne. On part de l'idée qu'envoyer plusieurs spikes en même temps permettrait la diminution de variance, en effet c'est comme si on répétait l'expérience plusieurs fois. Afin de voir si notre hypothèse est plausible, on va faire quelques simulations dans cette configuration.

\section{Variance pour \{20,40,60,80\}\textunderscore asend}

On va supposer que notre scénario de départ permet l'envoi de \{20,40,60,80\} en A (en haut à gauche du réseau). Puis on va observer la répartition des spikes sur la diagonale du réseau (de A à B - en bas à droite - ). On en déduit une variance ainsi qu'un intervalle de confiance pour cette variance.

\subsection{Utilisation du script}

Il suffit de run 

\begin{minted}[frame=single]{python} 
scilab -nw -f MultiBootstrap.sce
\end{minted}
 en ligne de commande. Ce script affiche la variance selon les configurations 20/40/60/80 ainsi que l'intervalle bootstrap à 95%.

\subsection{Résultats}

Pour commencer sous la contrainte de 5s de computation, on ne voit pas de grosses différences en terme de variance entre les 4 scénarios (20 40 60 80) comme on peut le constater sur \href{run:images/multibootstrap.png}{cette image}. Pour voir vraiment une différence, on voudrait augmenter le temps de computation. Le problème c'est que l'on change totalement les paramètres de départ, du coup on pourrait perdre des propriétés. En l'occurrence, on perd la forme désirée de la courbe (une demi gaussienne). Afin de trouver un moyen de diminuer la variance du modèle, il faut définir quelques contraintes. Plus précisément on doit garder la propriété d'additivité ainsi que la même forme de courbe.\\

{\color{red}\{TODO trouver un set de paramètre qui permettent de diminuer la variance.Si j'arrive pas avec paramètre jouer sur l'activation des neurones. 
Pourquoi on a ce comportement là (très varié) comment on peut l'améliorer ? Y réfléchir.
Quand j'ai trouvé un bon set de paramètre, vérifier si il y a bien additivité.\}}\\

Pistes pour diminuer la variance du routage : 

\begin{itemize}
	\item wrapper les maps (essayer d'abord avec un stimulis en milieu de map)
	\item connexion 8-connexe
	\item superposer plusieurs maps E et plusieurs map I et faire la moyenne
	\item rendre certains le transfert des spike aux quatres premiers voisins
	\item rendre des connexions obsolètes avec une ou deux computations suite au transfert d'un spike

\end{itemize}
 
%-----------------------------------------------------------------------------------------------



\part{Annexe}

%-----------------------------------------------------------------------------------------------



\part{TODO}

{\color{red}TODO expliquer les résultats pour avoir une meilleur compréhension des paramètres
\\TODO g1 additif,g2 additif =>? a*g1+b*g2+c additif =
\end{document}
